# Chapter 3 - Analytic

![analytics_chapter_3.png](..%2F..%2Fimg%2Fanalytics_chapter_3.png)

## Немного о продуктовых метриках

Некоторые примеры продуктовых метрик, которые можно отслеживать:

1. DAU, WAU, MAU: показатели количества активных пользователей по дням, неделям и месяцам
2. Конверсия: отношение числа пользователей, совершивших определенное действие (например, покупку), к общему числу посетителей.
3. Retention: вовлечённость пользователей и их срок жизни в нашем продукте.
4. Отказы: число пользователей, которые покинули приложение или сайт раньше, чем совершили определенное действие
5. ARPU/ARPPU: денежные показатели успешности нашего продукта на пользователя

**Дополнительные материалы**

- [про метрики мобильного приложения](https://www.youtube.com/watch?v=Ae0YO1izn84)
- рекомендую [этого спикера (Илья Красинский)](https://www.youtube.com/watch?v=h8VWl0GFW3Y) если вы хотите лучше погрузиться в мир продуктовой аналитики

## Базовые метрики Часть 1

Данные [data_part_1.sql](sql%2Fmigrations%2Fdata_part_1.sql)

Описание:
- **login** - заходы пользователей в приложение

1. event_time - время захода
2. uid - пользователь

- **funnel** - таблица с событиями

1. time - время события
2. event_type - тип события
3. uid - пользователь
4. user_reg_date - время регистрации

- **finance** - каждая строчка в этой таблице - отдельный платеж

1. event_time - это время платежа
2. price_usd - цена покупки
3. uid - пользователь
4. is_test - категория платежа, если is_test = 1 то платеж был тестовым

### Tasks

1. Посчитайте MAU за февраль 2023 года по таблице login

Агрегатные функции даты:
- toDate() - приведение к дате
- toMonday() - приведение к дате понедельника
- toStartOfMonth() - приведение к началу месяца

Решение [task_3_1_1_mau.sql](sql%2Fstaging%2Ftask_3_1_1_mau.sql)

2. Sticky Factor (Липкость) - отношение DAU/MAU то как часто пользователи заходят в приложение в течение месяца. 
Посчитайте данный показатель для month = '2023-01-01' возьмите avg от этого отношения.
Ответ: 4 знака после запятой

Решение [task_3_1_2_sticky.sql](sql%2Fstaging%2Ftask_3_1_2_sticky.sql)

3. Найдите пиковое значение(PCU) при агрегации данных по 5 минут!

**CCU (concurent users)** - число одновременных пользователей в продукте за небольшой промежуток времени

**PCU** - пиковое значение CCU за выбранный промежуток времени

Интересные функции:
- **toStartOfFiveMinutes** - агрегация по 5 минут
- **toStartOfFifteenMinutes** - агрегация по 15 минут

Решение [task_3_1_3_pcu.sql](sql%2Fstaging%2Ftask_3_1_3_pcu.sql)

4. Сколько новых пользователей пришедших в неделю начавшуюся 2023-02-13 совершили хотя бы один платеж?

Решение [task_3_1_4.sql](sql%2Fstaging%2Ftask_3_1_4.sql)

--------------------------------------------
## Базовые метрики Часть 2 (Монетизация)

### Tasks

1. Посчитать число первых платежей за дату 16 января в таблице finance Не забудьте отфильтровать по полю is_test

First Payment - до этой даты не было платежей.

Решение [task_3_2_1_first_payment.sql](sql%2Fstaging%2Ftask_3_2_1_first_payment.sql)

2. В какую из недель была максимальная выручка в таблице finance Не забудьте отфильтровать по полю is_test

Решение [task_3_2_1_max_revenue.sql](sql%2Fstaging%2Ftask_3_2_1_max_revenue.sql)

## Относительные метрики монетизации

К некоторым из них можно отнести:
- **ARPPU (Average Revenue Per Paying User)** - выручка, за отрезок времени, делённая на число уникальных платящих пользователей 

Это метрика, которая показывает средний доход с платящего пользователя.
Если ARPPU ниже чем бенчмарки(условно средние показатели по индустрии) - это может быть показателем того что надо работать над ценовой политикой и созданием более интересных предложений для пользователей.
 
- **Paying Share (доля платящих)** - число уникальных платящих деленное на число уникальных активных пользователей за отрезок времени

Если Paying Share ниже чем бенчмарки(условно средние показатели по индустрии) - возможно вам стоит сделать больший акцент на выгодных акциях и предложениях которые помогут пользователю конвертироваться в платящего.
 
- **ARPDAU (Average Revenue Per Daily Active User)** - сколько принес средний активный пользователь. Все деньги за период времени деленные на число активных пользователей 

Это метрика которая в целом показывает как продукт монетизирует активного пользователя. 
Её также используют в некоторых моделях прогнозирования выручки. 


### Tasks

1. Посчитать ARPMAU за март по таблицам login и finance Не забудьте отфильтровать по полю is_test
Ответ: 4 знака после запятой.

Решение: [task_3_2_2_arpmau.sql](sql%2Fstaging%2Ftask_3_2_2_arpmau.sql)

2. Посчитать процент платящей аудитории в марте по таблицам login и finance Не забудьте отфильтровать по полю is_test
Ответ 4 знака после запятой. В проценты переводить не нужно!

--------------------------------------------
## Когортные метрики - Часть 3

Что можно отследить с помощью когортного анализа:
- **Retention Rate** (уровень удержания пользователей)
- **Churn Rate** (коэффициент оттока пользователей)
- **Lifetime Value** (доход с пользователя за все время пользования им продукта)

Пример когортных метрик:
- **Registrations** - число пользователей в когорте
- **Retention D1** - доля пользователей зашедших на следующий день после регистрации
- **% PU** - конверсия в платящего в когорте (сколько пользователей из когорты заплатили хотябы раз)
- **CARPU day 0** - сколько принес пользователь из когорты в первый день жизни

## Funnel

### Tasks

1. Посчитайте воронку, в которой конверсия будет считаться не от общей аудитории, 
а из шага N в шаг N+1 по таблице funnel Такой метод расчета конверсии иногда используется чтобы сконцентрироваться на поведении пользователей между конкретными шагами. 
Вычислите отвал, конверсию, между level_2 и level_3

Решение [task_3_3_1_funnel.sql](sql%2Fstaging%2Ftask_3_3_1_funnel.sql)

## Retention

Два базовых подхода для расчета Retention:
- **Simple Retention** - сколько людей зашли на N-день после регистрации
Данный вид обычно используется в приложениях которые пользователи используют часто, например мобильная игра, новостной сайт
 
- **Rolling Retention** - сколько людей зашли на N и более день после регистрации. 
Данный показатель обычно используют для приложений которыми пользуется не часто, например банковское приложение, приложение для вызова такси.
Данный метод расчета позволяет сгладить проблему того что пользователи не будут заходить какое то время в приложение.

Разницу для себя объяснил рисунком:

![simple_vs_roll_retention.jpg](..%2F..%2Fimg%2Fsimple_vs_roll_retention.jpg)

Согласно рисунку для когорты 1 января:
1. Simple Retention3day = 5/10
2. Roll Retention3day = (все кто вернулся с 4 января и далее)/10

### Tasks

1. Посчитайте Rolling Retention 3 дня у когорты пришедшей 1 января по таблице login
2. Посчитайте отток (также через RollRetention) 3 дня у когорты пришедшей 1 января по таблице login

Решение [task_3_3_2_retention.sql](sql%2Fstaging%2Ftask_3_3_2_retention.sql)


## Накопительный ARPU

**Накопительный ARPU** показывает сколько денег принес в среднем один пользователь в когорте на N день жизни. 
Оценка сколько денег пользователь принесет за всю жизнь помогает понять сколько мы готовы заплатить за его привлечение, используется при оценке маркетинговых бюджетов. 


### Tasks

Посчитайте **Накопительный ARPPU** 15 дня жизни для тех кто зарегистрировался 2023-02-27. 

Уточнение, **Накопительный ARPPU** отличается от **Накопительный ARPU** тем что мы считаем только заплативших пользователей, не забудьте уточнить это в вашем запросе! Тестовые платежи убираем.

Формат ответа: Ответ до 4 знака после запятой.


Решение [task_3_3_3.sql](sql%2Fstaging%2Ftask_3_3_3.sql)


## LTV

**LTV (Lifetime Value)** - это метрика, которая показывает, сколько денег принесет продукту один пользователь в течение своей жизни. 
Она выражается в денежном эквиваленте и помогает оценить эффективность привлечения и удержания пользователей.

Существует несколько видов **LTV (Lifetime Value)**:

- **Gross LTV** - это суммарная стоимость всех покупок, совершенных одним пользователем в течение его жизни. 
Этот вид LTV не учитывает расходы на привлечение и удержание пользователей.
- **Net LTV** - это суммарная стоимость всех покупок, совершенных одним пользователем в течение его жизни, минус расходы на привлечение и удержание этого пользователя. 
Этот вид LTV учитывает расходы и позволяет оценить рентабельность инвестиций в пользователей.
- **Predicted LTV** - это прогнозируемая суммарная стоимость всех покупок, которые совершит один пользователь в течение своей жизни. 
Этот вид LTV основан на анализе исторических данных. (его мы и будем пытаться посчитать)

Чтобы предсказать LTV, нужно использовать анализ исторических данных о покупках пользователей. 
Обычно это делается с помощью математических моделей, например, модели регрессии. 


Данные для прогнозирования LTV [data_ltv_forecast.sql](sql%2Fmigrations%2Fdata_ltv_forecast.sql)

1. Тк дни могут быть не все, то необходимо сгенерировать каждый день жизни когорты от 1 до N

Исходные данные (для когорты 2 нет дней 1, 4, 6 и др):

![ltv_raw_data.png](..%2F..%2Fimg%2Fltv_raw_data.png)


2. Генерим все дни:

![ltv_data_ml.png](..%2F..%2Fimg%2Fltv_data_ml.png)

3. Для прогнозирования необходимо свернуть данные в массив (чтобы не было 0, при сворачивании используется arrayCumSum

```sql
SELECT cohort,
       groupArray(DAY) AS X, -- сворачиваем в массив
       arrayCumSum(groupArray(value)) AS y -- считаем накопительную выручку
FROM  data_ml
group by cohort;
```

![ltv_arrays.png](..%2F..%2Fimg%2Fltv_arrays.png)


4. Далее применяется логарифмирование, чтобы линеаризовать зависимость, формируется массив для прогнозирования:

```sql
CREATE VIEW predict_ml AS
SELECT cohort,
       groupArray(DAY) AS X,
       arrayCumSum(groupArray(value)) AS y,
       arrayMap(x -> ln(x + 2),X) AS X_ln, -- формула по которой считаем, можно задать любую другую
       arrayReduce('simpleLinearRegression', X_ln, y) AS coef, -- прогнозирвоание с помощью простой линейной регрессии

       /* Все последующие преобразования нужны для прогноза выручки на N день */
       length(X_ln) AS count_days, -- Считаем количество дней

       arrayMap(x -> ln(x + 2), range(length(X_ln) + 30)) AS days_predict, -- Применяем функцию к данным + 30 дней,

       tupleElement(coef, 1) AS coef_a,
       tupleElement(coef, 2) AS coef_b,
       arrayMap(x -> x * coef_a + coef_b, days_predict) AS array_predict
FROM  data_ml
group by cohort;
```

5. Чтобы развернуть данные из массива:

```sql
SELECT cohort,
       arrayJoin(range(count_days + 30)) AS index_days, -- Формируем список из 30 дней
       arrayElement(array_predict, index_days + 1) AS predict, -- Извлекаем из полчившегося массива ДНИ
       arrayElement(y, index_days + 1) AS revenue -- Извлекаем из полчившегося массива ВЫРУЧКА
FROM predict_ml
```

Смотрим на фактические значения и прогноз:

![ltv_forecast_compare.png](..%2F..%2Fimg%2Fltv_forecast_compare.png)

Видно, что различия существенные, но для простой прикидки достаточно (так сказать, чтобы не промахнуться на километр))

Строим график:

![ltv_forecast_plot.png](..%2F..%2Fimg%2Fltv_forecast_plot.png)

### Tasks

В данном задании нужно адаптировать данный запрос к нашим данным, воспользуйтесь таблицами login и finance. 
Для этого, посчитайте прогноз на 50 день жизни когорты для пользователей зарегистрировавшихся в эти дни: 2023-01-01, 2023-01-02, 2023-01-03

В качестве ответа предоставьте SQL запрос.

Запрос подготавливающий данные в виде `когорта-lifetime-ltv`

```postgres-sql
SELECT first_reg_date, 
			   lifetime,
			   uniq(uid) AS users,
			   sum(price_usd) AS revenue
		FROM 
			(select *,
				   date_diff('day', first_reg_date, toDate(event_time)) + 1 AS lifetime -- вычисление lifetime
			from 
				-- JOIN события + когорта
					(--объединение login + finance
				    SELECT
				        event_time
				        , 'login' as event_type
				        , uid
				        , 0 as price_usd
				    FROM login
				    UNION ALL
				    SELECT
				        event_time
				        , 'finance' as event_type
				        , uid
				        , revenue_usd as price_usd
				    FROM finance
				    WHERE is_test = 0) t1
				any left join (SELECT uid,
				                     min(toDate(event_time)) as first_reg_date
				              FROM login
				              GROUP BY uid) t2
				using uid
				WHERE first_reg_date IN ('2023-01-01', '2023-01-02', '2023-01-03')
				ORDER BY first_reg_date, lifetime)
		GROUP BY first_reg_date, lifetime
		ORDER BY first_reg_date, lifetime
```

И важная деталь, в момент схлопывания данные в массивы (для прогнозирования) идет расчет LTV:

```postgres-sql
arrayMap(x -> x / max(users), groupArrayMovingSum(revenue)) AS y, --расчет LTV=CumRevenue / cohort_size
```

Полное решение [task_3_4_1_ltv_forecast.sql](sql%2Fstaging%2Ftask_3_4_1_ltv_forecast.sql)


![ltv_forecast_meme.png](..%2F..%2Fimg%2Fltv_forecast_meme.png)